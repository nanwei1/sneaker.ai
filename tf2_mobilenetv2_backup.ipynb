{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# set up tensorboard log directory\n",
    "logdir=\"tf_logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "os.makedirs(logdir, exist_ok=True)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "# need the following to successfully run. \n",
    "# Otherwise there will be cuDNN error in training \n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "sess.as_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "import random\n",
    "# import tensorflow_addons as tfa\n",
    "\n",
    "# define dataloader and preprocessing\n",
    "def load_and_preprocess_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    return preprocess_image(image)\n",
    "\n",
    "# the following does not work with eager execution\n",
    "def preprocess_image(image, rotate_range=30):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = image/255  # normalize to [0,1] range    \n",
    "    image = tf.image.resize_with_pad(image, 256, 256)\n",
    "    \n",
    "    # tf2.0 does not have tf.contrib which contains random rotation\n",
    "    # Was able to find alternative in tensorfow_addons\n",
    "    # But there is ongoing issue with rotate: https://github.com/tensorflow/addons/issues/94\n",
    "    # The following causes \n",
    "#     rotate_angle = tf.random.uniform(shape=[1], minval=-rotate_range/180*3.14, maxval=rotate_range/180*3.14)\n",
    "#     rot_transform = tfa.image.transform_ops.angles_to_projective_transforms(rotate_angle, 256, 256)\n",
    "#     image = tfa.image.transform(image, rot_transform)\n",
    "    \n",
    "    image = tf.image.random_crop(image, (224, 224, 3))\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, 0.2)\n",
    "    image = tf.image.random_contrast(image, 0.8, 1.2)\n",
    "    image = tf.image.random_saturation(image, 0.8, 1.2)\n",
    "    image = tf.clip_by_value(image, 0, 1)\n",
    "    # tensorflow2.0 does not have tf.conrib.image.rotate()\n",
    "#     image = tf.convert_to_tensor(skimage.transform.rotate(image.numpy(), rot_angle))\n",
    "    return image\n",
    "\n",
    "# # define dataloader and preprocessing\n",
    "# def load_and_preprocess_image(path):\n",
    "#     image = tf.io.read_file(path)\n",
    "#     return preprocess_image(image)\n",
    "\n",
    "# # the following does not work with eager execution\n",
    "# def preprocess_image(image):\n",
    "#     image = tf.image.decode_jpeg(image, channels=3)\n",
    "#     image = image/255  # normalize to [0,1] range\n",
    "#     # randomly rotate image for data augmentation\n",
    "#     rotate_range=30\n",
    "#     rot_angle = random.randint(-rotate_range, rotate_range)\n",
    "#     image = tf.convert_to_tensor(skimage.transform.rotate(image.numpy(), rot_angle))\n",
    "#     image = tf.image.resize_with_pad(image, 256, 256)\n",
    "#     image = tf.image.random_crop(image, (224, 224, 3))\n",
    "#     image = tf.image.random_flip_left_right(image)\n",
    "#     image = tf.image.random_brightness(image, 0.3)\n",
    "#     image = tf.image.random_contrast(image, 0.7, 1.3)\n",
    "#     image = tf.image.random_saturation(image, 0.7, 1.3)\n",
    "#     # tensorflow2.0 does not have tf.conrib.image.rotate()\n",
    "# #     image = tf.convert_to_tensor(skimage.transform.rotate(image.numpy(), rot_angle))\n",
    "#     return image\n",
    "\n",
    "# def load_and_preprocess_image(path):\n",
    "#     return preprocess_image(path)\n",
    "# def preprocess_image(image):\n",
    "#     image = skimage.io.imread(image)\n",
    "# #     image = tf.image.decode_jpeg(image, channels=3)\n",
    "#     image = image/255  # normalize to [0,1] range\n",
    "#     # randomly rotate image for data augmentation\n",
    "# #     print(image)\n",
    "#     rotate_range=30\n",
    "#     rot_angle = random.randint(-rotate_range, rotate_range)\n",
    "#     image = skimage.transform.rotate(image, rot_angle)\n",
    "#     image = tf.convert_to_tensor(image)\n",
    "#     image = tf.image.resize_with_pad(image, 256, 256)\n",
    "#     image = tf.image.random_crop(image, (224, 224, 3))\n",
    "#     image = tf.image.random_flip_left_right(image)\n",
    "#     image = tf.image.random_brightness(image, 0.3)\n",
    "#     image = tf.image.random_contrast(image, 0.7, 1.3)\n",
    "#     image = tf.image.random_saturation(image, 0.7, 1.3)\n",
    "#     # tensorflow2.0 does not have tf.conrib.image.rotate()\n",
    "# #     image = tf.convert_to_tensor(skimage.transform.rotate(image.numpy(), rot_angle))\n",
    "#     return image\n",
    "\n",
    "path = \"/home/nan/sneaker_ai/screened_data/air_jordan_1/air_jordan_1_362.png\"\n",
    "plt.imshow(load_and_preprocess_image(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test random data loaders\n",
    "train_df = pd.read_csv(\"train_df.csv\")\n",
    "indx = random.randint(0, len(train_df))\n",
    "path = train_df.iloc[indx, 1]\n",
    "print(path)\n",
    "plt.imshow(load_and_preprocess_image(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up datasets\n",
    "from sklearn.utils import shuffle\n",
    "train_df = shuffle(train_df)\n",
    "train_image_paths = train_df.loc[:, \"Image_File\"].tolist()\n",
    "train_image_labels = train_df.loc[:, \"Label\"].tolist()\n",
    "\n",
    "test_df = pd.read_csv(\"test_df.csv\")\n",
    "# test_df = shuffle(test_df)\n",
    "test_image_paths = test_df.loc[:, \"Image_File\"].tolist()\n",
    "test_image_labels = test_df.loc[:, \"Label\"].tolist()\n",
    "# covertion between class names and model outputs\n",
    "label_names = [\"AJ \"+str(i) for i in range(1,24)]\n",
    "label_to_index = dict((name, index) \n",
    "                      for index, name in enumerate(label_names))\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_image_paths, train_image_labels))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_image_paths, test_image_labels))\n",
    "\n",
    "# The tuples are unpacked into the positional arguments of the mapped function \n",
    "def load_and_preprocess_from_path_label(path, label):\n",
    "    return load_and_preprocess_image(path), label\n",
    "\n",
    "train_ds = train_ds.map(load_and_preprocess_from_path_label)\n",
    "test_ds = test_ds.map(load_and_preprocess_from_path_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify batch size and buffering for datasets\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# # Setting a shuffle buffer size as large as the dataset ensures that the data is\n",
    "# # completely shuffled.\n",
    "# train_ds = train_ds.apply(\n",
    "#   tf.data.experimental.shuffle_and_repeat(buffer_size=len(train_df)))\n",
    "# do the following to save some ram, otherwise training will stop\n",
    "train_ds = train_ds.apply(\n",
    "  tf.data.experimental.shuffle_and_repeat(buffer_size=256))\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "train_ds = train_ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# do the following to save some ram, otherwise training will stop\n",
    "test_ds = test_ds.apply(\n",
    "  tf.data.experimental.shuffle_and_repeat(buffer_size=256))\n",
    "# test_ds = test_ds.apply(\n",
    "#   tf.data.experimental.shuffle_and_repeat(buffer_size=len(test_df)))\n",
    "test_ds = test_ds.batch(BATCH_SIZE)\n",
    "test_ds = test_ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mobilenet v2 model\n",
    "mobile_net = tf.keras.applications.MobileNetV2(input_shape=(224,224, 3), include_top=False)\n",
    "# mobile_net.trainable=False\n",
    "mobile_net.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNetV2: https://github.com/keras-team/keras-applications/blob/master/keras_applications/mobilenet_v2.py\n",
    "# imagenet.utils: https://github.com/keras-team/keras-applications/blob/master/keras_applications/imagenet_utils.py\n",
    "# mobile net expects prepocessed input ranging from -1 to 1\n",
    "def change_range(image,label=0):\n",
    "    return 2*image-1, label\n",
    "\n",
    "train_ds = train_ds.map(change_range)\n",
    "test_ds = test_ds.map(change_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularizer = 0.05;\n",
    "# add fc layers after mobilenet for transfer learning\n",
    "model = tf.keras.Sequential([\n",
    "    mobile_net,\n",
    "    # take an average of each channel so that the model woks with different input sizes\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "#     tf.keras.layers.Dense(512, activation = tf.nn.relu),\n",
    "    tf.keras.layers.Dense(256, activation = tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(regularizer)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "#     tf.keras.layers.Dense(128, activation = tf.nn.relu),\n",
    "    tf.keras.layers.Dense(64, activation = tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(regularizer)),\n",
    "#     tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(len(label_names), activation=tf.nn.softmax, kernel_regularizer=tf.keras.regularizers.l2(regularizer))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure model optimizer, loss\n",
    "# model.compile(optimizer=tf.optimizers.Adam(learning_rate=5e-6), \n",
    "#               loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "#               metrics=[\"accuracy\"])\n",
    "\n",
    "# learning_rate=5e-6 was tuned for batch size 16\n",
    "# larger batch allows for greater learning rate\n",
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=8e-5), \n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir {logdir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training\n",
    "num_epochs = 30\n",
    "training_history = model.fit(train_ds, epochs=num_epochs, \n",
    "                             validation_data=test_ds,\n",
    "                             callbacks=[tensorboard_callback],\n",
    "                             verbose=2,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(model, os.path.join(logdir, \"model\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training and validation history\n",
    "hist = training_history.history\n",
    "train_loss = hist[\"loss\"]\n",
    "test_loss = hist[\"val_loss\"]\n",
    "train_accuracy = hist[\"accuracy\"]\n",
    "test_accuracy = hist[\"val_accuracy\"]\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(2,1,1)\n",
    "ax = plt.gca()\n",
    "ax.set_xlim([0, len(train_loss) + 1])\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(range(1, len(train_loss)+1), train_loss, 'r', label='Training Loss')\n",
    "plt.plot(range(1, len(test_loss)+1), test_loss, 'b', label='Test Loss')\n",
    "ax.grid(linestyle='-.')\n",
    "plt.legend()\n",
    "plt.subplot(2,1,2)\n",
    "ax = plt.gca()\n",
    "ax.set_xlim([0, len(train_accuracy) + 1])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(range(1, len(train_accuracy)+1), train_accuracy, 'r', label='Training Accuracy')\n",
    "plt.plot(range(1, len(test_accuracy)+1), test_accuracy, 'b', label='Test Accuracy')\n",
    "ax.grid(linestyle='-.')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(logdir, 'training_hist.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def img_preprocessing(path):\n",
    "#     img = load_and_preprocess_image(path)\n",
    "#     img, _ = change_range(img,label=0)\n",
    "#     return img\n",
    "\n",
    "def img_preprocessing(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = image/255  # normalize to [0,1] range\n",
    "    image = tf.image.resize_with_pad(image,224,224)\n",
    "    image, _ = change_range(image,label=0)\n",
    "    return image\n",
    "\n",
    "test_df = pd.read_csv(\"test_df.csv\")\n",
    "test_image_paths = test_df.loc[:, \"Image_File\"].tolist()\n",
    "test_image_labels = test_df.loc[:, \"Label\"].tolist()\n",
    "\n",
    "rand_indx = random.randint(0, len(test_image_paths)-1)\n",
    "img = img_preprocessing(test_image_paths[rand_indx]) \n",
    "plt.imshow((img+1)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images=100\n",
    "classes = [\"AJ \"+str(i) for i in range(1,24)]\n",
    "indices = np.random.choice(len(test_image_paths), num_images, replace=False)\n",
    "inputs = np.empty(shape=(num_images,224,224,3))\n",
    "targets = np.empty(shape=(num_images))\n",
    "for i, indx in enumerate(indices):\n",
    "    inputs[i,:,:,:] = img_preprocessing(test_image_paths[indx]).numpy()\n",
    "    targets[i] = test_image_labels[indx]\n",
    "output = model.predict(inputs)\n",
    "prediction = output.argmax(axis=1)\n",
    "targets = targets.astype(int)\n",
    "# output.shape\n",
    "# output.argmax(axis=1)==targets\n",
    "\n",
    "images_so_far = 0\n",
    "fig = plt.figure(figsize=(16,40))\n",
    "\n",
    "for i in range(num_images):\n",
    "    images_so_far += 1\n",
    "    ax = plt.subplot(num_images//5, 5, images_so_far)\n",
    "    ax.axis('off')\n",
    "    ax.set_title('Actual:{}, Predicted:{}'.format(classes[targets[i]], classes[prediction[i]]),\n",
    "    color = 'k' if targets[i]==prediction[i] else 'r' )\n",
    "    plt.imshow((inputs[i,:,:,:]+1)/2)  # need to transform range from [-1,1] to [0,1]\n",
    "\n",
    "plt.savefig(os.path.join(logdir, 'example_output.png'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
