{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import itertools\n",
    "import logging\n",
    "import re\n",
    "import os\n",
    "import uuid\n",
    "import sys\n",
    "from urllib2 import urlopen, Request\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_logging():\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(\n",
    "        logging.Formatter('[%(asctime)s %(levelname)s %(module)s]: %(message)s'))\n",
    "    logger.addHandler(handler)\n",
    "    return logger\n",
    "logger = configure_logging()\n",
    "\n",
    "REQUEST_HEADER = {\n",
    "    'User-Agent': \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.134 Safari/537.36\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url, header):\n",
    "    response = urlopen(Request(url, headers=header))\n",
    "    return BeautifulSoup(response, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_url(query):\n",
    "    return \"https://www.google.co.in/search?q=%s&source=lnms&tbm=isch\" % query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images_from_soup(soup):\n",
    "    image_elements = soup.find_all(\"div\", {\"class\": \"rg_meta\"})\n",
    "    metadata_dicts = (json.loads(e.text) for e in image_elements)\n",
    "    link_type_records = ((d[\"ou\"], d[\"ity\"]) for d in metadata_dicts)\n",
    "    return link_type_records\n",
    "\n",
    "def extract_images(query, num_images):\n",
    "    url = get_query_url(query)\n",
    "    logger.info(\"Souping\")\n",
    "    soup = get_soup(url, REQUEST_HEADER)\n",
    "    logger.info(\"Extracting image urls\")\n",
    "    link_type_records = extract_images_from_soup(soup)\n",
    "    return itertools.islice(link_type_records, num_images)\n",
    "\n",
    "def get_raw_image(url):\n",
    "    req = Request(url, headers=REQUEST_HEADER)\n",
    "    resp = urlopen(req)\n",
    "    return resp.read()\n",
    "\n",
    "def save_image(raw_image, image_type, save_directory):\n",
    "    extension = image_type if image_type else 'jpg'\n",
    "    file_name = str(uuid.uuid4().hex) + \".\" + extension\n",
    "    save_path = os.path.join(save_directory, file_name)\n",
    "    with open(save_path, 'wb+') as image_file:\n",
    "        image_file.write(raw_image)\n",
    "\n",
    "def download_images_to_dir(images, save_directory, num_images):\n",
    "    for i, (url, image_type) in enumerate(images):\n",
    "        try:\n",
    "            logger.info(\"Making request (%d/%d): %s\", i, num_images, url)\n",
    "            raw_image = get_raw_image(url)\n",
    "            save_image(raw_image, image_type, save_directory)\n",
    "        except Exception as e:\n",
    "            logger.exception(e)\n",
    "            \n",
    "def run(query, save_directory, num_images=100):\n",
    "    query = '+'.join(query.split())\n",
    "    logger.info(\"Extracting image links\")\n",
    "    images = extract_images(query, num_images)\n",
    "    logger.info(\"Downloading images\")\n",
    "    download_images_to_dir(images, save_directory, num_images)\n",
    "    logger.info(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-s SEARCH] [-n NUM_IMAGES] [-d DIRECTORY]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /run/user/1000/jupyter/kernel-74dc1d91-7b4f-4f55-a32d-8fb9583b1f47.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nan/anaconda3/envs/scrape_img/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2886: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='Scrape Google images')\n",
    "    parser.add_argument('-s', '--search', default='bananas', type=str, help='search term')\n",
    "    parser.add_argument('-n', '--num_images', default=1, type=int, help='num images to save')\n",
    "    parser.add_argument('-d', '--directory', default='/Users/gene/Downloads/', type=str, help='save directory')\n",
    "    args = parser.parse_args()\n",
    "    run(args.search, args.directory, args.num_images)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
